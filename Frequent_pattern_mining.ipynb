{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Orange\n",
    "from orangecontrib.associate.fpgrowth import *  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_creations_df = pd.read_csv(f'data/all_label_creations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort revisions by properties and timestamps\n",
    "label_creations_df.sort_values([\"property\",\"timestamp\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a position for each label\n",
    "#\n",
    "# e.g. 1 means first label created\n",
    "#      n means n label translated\n",
    "\n",
    "last_prop,i,position = None,1,[]\n",
    "\n",
    "for index, row in label_creations_df.copy().iterrows():\n",
    "    if(row['property'] != last_prop):\n",
    "        i, last_prop = 1, row['property']\n",
    "    position.append(i)\n",
    "    i += 1\n",
    "\n",
    "label_creations_df['position'] = position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe given the revision's history for each property\n",
    "revisions_history_df= pd.pivot_table(data=label_creations_df,\n",
    "                                     index=\"property\",\n",
    "                                     columns=\"position\",\n",
    "                                     values='language',\n",
    "                                     aggfunc=lambda x: ' '.join(x))\n",
    "\n",
    "revisions_history_df.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionnaries to easily encode and decode the languages\n",
    "languages = label_creations_df.language.unique()\n",
    "code_to_language = {i:el for i,el in enumerate(languages)}\n",
    "language_to_code = {el:i for i,el in code_to_language.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_code_list(l):\n",
    "    return [code_to_language[i] for i in list(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_language_list(l):\n",
    "    return [language_to_code[i] for i in list(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert revisions_history_df to a format accepted by Orange to mine the frequent patterns\n",
    "history = []\n",
    "for _,row in revisions_history_df.iterrows():\n",
    "    history.append([language_to_code[el] for el in row.values if el])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent items analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of properties: 190\n"
     ]
    }
   ],
   "source": [
    "# Number of propeties\n",
    "print(\"Number of properties: {0}\".format(len(history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 items have a support greater than 0.6\n"
     ]
    }
   ],
   "source": [
    "# Count items \n",
    "sum_items = len(list(frequent_itemsets(history, min_support)))                \n",
    "print(\"{0} items have a support greater than {1}\".format(sum_items,min_support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterable = [(support,decode_code_list(itemset)) for itemset, support in frequent_itemsets(history,min_support)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent(history, item_len, min_support):\n",
    "    \"\"\"\n",
    "    Input: - history,\n",
    "           - item_len, lenght of the most frequent items\n",
    "           - min_support, percentage, if this value is too low you might have performance issues\n",
    "    \n",
    "    Output: sorted list of most frequent items\n",
    "    \n",
    "    \"\"\"\n",
    "    gen = frequent_itemsets(history,min_support)\n",
    "    decoded_itemsets = [(support,decode_code_list(itemset)) for itemset, support in gen if len(itemset) == item_len]\n",
    "    return list(reversed(sorted(decoded_itemsets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(190, ['en']),\n",
       " (188, ['ar']),\n",
       " (187, ['fr']),\n",
       " (185, ['uk']),\n",
       " (147, ['nl']),\n",
       " (134, ['mk']),\n",
       " (133, ['es']),\n",
       " (123, ['de']),\n",
       " (120, ['ru']),\n",
       " (110, ['pl']),\n",
       " (110, ['ca']),\n",
       " (101, ['it']),\n",
       " (99, ['sr']),\n",
       " (82, ['zh-hans']),\n",
       " (82, ['ko']),\n",
       " (79, ['nb']),\n",
       " (77, ['hu']),\n",
       " (77, ['da']),\n",
       " (74, ['pt']),\n",
       " (66, ['ja']),\n",
       " (59, ['cs']),\n",
       " (57, ['fa']),\n",
       " (52, ['be-tarask']),\n",
       " (49, ['zh-hant']),\n",
       " (48, ['sv']),\n",
       " (48, ['he']),\n",
       " (48, ['fi'])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(history, 1 ,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rules analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object frequent_itemsets at 0x1394daba0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets(history,min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({75, 98})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset({75, 98})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# association of the 4 most commun languages\n",
    "cl = ['en','ar','fr','uk']\n",
    "itemset = frozenset(code_language_list(cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, ['en', 'ar', 'uk', 'ko'], ['fr'], 81),\n",
       " (1.0, ['en', 'ar', 'ko', 'fr'], ['uk'], 81),\n",
       " (1.0, ['en', 'ar', 'ko'], ['uk', 'fr'], 81),\n",
       " (1.0, ['ar', 'uk', 'ko', 'fr'], ['en'], 81),\n",
       " (1.0, ['ar', 'uk', 'ko'], ['en', 'fr'], 81),\n",
       " (1.0, ['ar', 'ko', 'fr'], ['en', 'uk'], 81),\n",
       " (1.0, ['ar', 'ko'], ['en', 'uk', 'fr'], 81),\n",
       " (0.9878048780487805, ['uk', 'ko', 'fr'], ['en', 'ar'], 81),\n",
       " (0.9878048780487805, ['uk', 'ko'], ['en', 'ar', 'fr'], 81),\n",
       " (0.9878048780487805, ['ko', 'fr'], ['en', 'ar', 'uk'], 81),\n",
       " (0.9878048780487805, ['ko'], ['en', 'ar', 'uk', 'fr'], 81),\n",
       " (0.9878048780487805, ['en', 'uk', 'ko', 'fr'], ['ar'], 81),\n",
       " (0.9878048780487805, ['en', 'uk', 'ko'], ['ar', 'fr'], 81),\n",
       " (0.9878048780487805, ['en', 'ko', 'fr'], ['ar', 'uk'], 81),\n",
       " (0.9878048780487805, ['en', 'ko'], ['ar', 'uk', 'fr'], 81),\n",
       " (0.45, ['en', 'ar', 'uk', 'fr'], ['ko'], 81),\n",
       " (0.45, ['ar', 'uk', 'fr'], ['en', 'ko'], 81),\n",
       " (0.44505494505494503, ['uk', 'fr'], ['en', 'ar', 'ko'], 81),\n",
       " (0.44505494505494503, ['en', 'uk', 'fr'], ['ar', 'ko'], 81),\n",
       " (0.4426229508196721, ['en', 'ar', 'uk'], ['ko', 'fr'], 81),\n",
       " (0.4426229508196721, ['ar', 'uk'], ['en', 'ko', 'fr'], 81),\n",
       " (0.43783783783783786, ['uk'], ['en', 'ar', 'ko', 'fr'], 81),\n",
       " (0.43783783783783786, ['en', 'uk'], ['ar', 'ko', 'fr'], 81),\n",
       " (0.43783783783783786, ['en', 'ar', 'fr'], ['uk', 'ko'], 81),\n",
       " (0.43783783783783786, ['ar', 'fr'], ['en', 'uk', 'ko'], 81),\n",
       " (0.43315508021390375, ['fr'], ['en', 'ar', 'uk', 'ko'], 81),\n",
       " (0.43315508021390375, ['en', 'fr'], ['ar', 'uk', 'ko'], 81),\n",
       " (0.4308510638297872, ['en', 'ar'], ['uk', 'ko', 'fr'], 81),\n",
       " (0.4308510638297872, ['ar'], ['en', 'uk', 'ko', 'fr'], 81),\n",
       " (0.4263157894736842, ['en'], ['ar', 'uk', 'ko', 'fr'], 81)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsets_dict = dict(frequent_itemsets(history))\n",
    "rules = association_rules(itemsets_dict,0.003,itemset)\n",
    "decoded_itemsets = [(confidence, decode_code_list(antecedent),decode_code_list(consequent),support) for antecedent,consequent,support,confidence in list(rules)]\n",
    "list(reversed(sorted(decoded_itemsets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
